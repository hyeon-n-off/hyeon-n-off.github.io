---
title: "Computer Vision Basic: Convolution Neural Network"
date: 2024-04-06 00:00:00 +09:00
categories: [Computer Vision Basic]
tags:
  [
    Computer Vision Basic,
    CNN(Convolution Neural Network),
  ]
---

## **모델의 구조**
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/d52c8dca-d249-4220-bd9a-334f93f32106)

**Visual Feature**: 컴퓨터 비전 태스크(e.g. classification, detection, segmentation, ...)를 해결할 때 필요한 이미지의 특성을 담고 있는 정보  <br>

### **Backbone Layer**
> 이미지에서 중요한 Feature를 추출할 수 있도록 훈련되는 층  <br>
> <br>
> 즉, Backbone의 역할은 <span style="background-color:#fff5b1">**주어진 비전 태스크를 잘 수행할 수 있는 압축된 Visual Feature를 산출**</span>하는 것이다.  <br>
> ![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/980fb50b-041d-4c5f-874d-a2852342e5ad)
> <br>
> <br>
> <br>
> Backbone은 여러 개의 Layer로 이루어져 있고, 이를 통해 다양한 Level의 Feature를 추출할 수 있다.
> ![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/cb4e903b-ef9a-475e-836a-b6550425c01e)

<hr>

### **Decoder**
> 압축된 Feature를 목표하는 태스크의 출력 형태로 만드는 과정을 수행한다.  <br>
> ![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/3b7cd1cc-fdc0-4647-8303-949543cfc851)

<hr>

## **기본적인 개념**
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/2b55fb1d-26f9-4886-800d-536b5d31dfc2)

### **Convolution Layer**
모델 네트워크가 비전 태스크를 수행하는 데 유용한 Feature들을 학습할 수 있도록 한다.  <br>
**Filter(Kernel)**: 입력 이미지를 특정 크기의 Filter를 이용해 탐색하면서 Convolution 연산을 수행한다.  <br>
이를 통해 이미지에 대한 특징을 추출할 수 있다.  <br>
<br>

![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/a236833d-5915-44af-a857-f9d043053917){: width='60%'}

![ezgif com-animated-gif-maker](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/760cf0f2-f946-48ca-890c-4967f5ab88fc)

Convolution Layer를 여러개 쌓는 경우, 뒤 레이어의 결괏값 하나를 만드는데 사용되는 이미지 범위가 넓어진다.  <br>
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/afcc4021-c4bd-4944-a065-25ec75b8ad6b)

<br>
따라서, Convolution 초반 Layer의 경우 edge와 같은 low-level feature를 주로 학습하게되고, 후반 Layer의 경우 shape과 같은 high-level feature를 주로 학습하게된다.  <br>

### **Batch Normalization**
1. Deep Network가 잘 학습될 수 있도록 한다.
2. Gradient flow를 개선시킨다.
3. 더 빠르게 수렴할 수 있게 한다.
4. 학습 시 정규화 효과를 가져온다.
5. 좀 더 강건한 모델이 될 수 있게 도와준다. (과적합을 방지해준다.)
6. <span style="background-color:#fff5b1">**주로 Convolution Layer과 Activation Layer 사이에 위치시킨다.**</span>

![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/ed9719b5-78e1-4081-bd71-829016462837)

### **Activation Function**
모델이 비선형성을 가질 수 있도록 만들어준다. 복잡한 문제를 해결하기 위해서는 비선형성을 지닌 모델이 유리하다.  <br>

![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/f50169c2-9f7c-4979-a7ec-a508a0796d3c)

<br>

Q. Convolution Layer로는 비선형성을 가질 수 없나?  <br>
A. Yes! Convolution 연산 결과 1차 함수를 얻게 되므로 Convolution Layer만으로는 선형적인 모델만 만들 수 있다.  <br>
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/6904d884-3fef-4f02-b2ad-0bd66a167e06)  <br>


### **Pooling Layer**
Feature Map에 Spatial Aggregation을 시켜준다.  <br>
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/f88fd764-5290-446a-ae6e-4abc9d56c074)

모델의 파라미터 수를 줄일 수 있으며, 더 넓은 Receptive Field를 볼 수 있게 해준다.  <br>

> **Max Pooling vs Averge Pooling**  <br>
> **Max Pooling의 단점: 정보의 손실이 일어날 수 있다.**
> ![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/0747c6c5-2dbb-4666-9ecd-d547d95e4718){: width='70%'}
> <br>
>
> **Average Pooling의 단점: 중요한 정보가 희석될 수 있다.**
> ![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/79666c46-6f84-4493-9e10-9423f6c7a6f2){: width='70%'}

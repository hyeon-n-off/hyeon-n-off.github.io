---
title: "Computer Vision Basic: CAM과 Grad-CAM"
date: 2024-04-06 00:00:00 +09:00
categories: [Computer Vision Basic]
tags:
  [
    Computer Vision Basic,
    Class Activation Mapping(CAM),
  ]
---

## 설명가능한 AI(Explainable AI, XAI)
- 기존의 AI는 블랙박스라는 이야기가 많았다. 이는 모델의 판단에 대해 모델을 제안한 사람도, 코드를 짠 사람도 설명할 수 없는 이유에서였다.
- 간단한 문제에서부터 자율 주행, 수술 등 섬세하고 인간의 안전과 생명에 영향을 미치는 문제에 AI가 자리를 차지하기 시작하면서 이에 대한 우려는 더욱 커졌다.
- 이러한 배경 속에서 XAI에 대한 관심이 커졌다. XAI 모델 중 하나인 CAM에 대해 알아보자.

### CAM (Class Activation Map)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/d02af537-2ff0-4c39-ad00-c861fb92db67)

1. 보통의 CNN classification 문제에서 Backbone Layer를 거친 후 Fully Connected Layer를 통해 Flatten한 후 우리가 원하는 카테코리의 크기로 해당 카테고리의 확률을 출력한다. (softmax)
2. 그러나, 이 과정에서 FC Layer를 사용하면 Pixel의 공간 정보를 잃게된다.
3. Flatten 하는 대신, GAP(Global Average Pooling)을 거치게 되면, Feature Map 당 하나의 특징 변수(F_k)로 변환하게 된다.

→ FC Layer 대신 GAP를 수행하여 각 클래스로 분류될 확률에 영향을 미친 객체의 좌표(x, y)를 추출할 수 있다.  <br>
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/75c93886-209c-41c3-9580-4fa28d3d5e4d)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/15e61114-a14b-4fb7-8b90-de47c97add45){: width='60%'}
<br>

![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/6f2960ee-771c-4679-a492-4183ebe1a513){: width='60%'}
<br>

```python
# 우리가 필요한 것
# 1. FC Layer의 weight
# 2. 마지막 Convolution Feature Map

# =============[1. FC Layer weight]=============
params = list(model.parameters())

# params[-1]: fc layer의 bias
# params[-2]: fc layer의 weight
fc_weight = np.squeeze(params[-2].cpu().detach().numpy())
# ==============================================

# =============[2. Last Feature Map]=============
# 마지막 Convolution Layer 찾기
last_conv_layer = None
for layer in model.modules():
    if isinstance(layer, nn.Conv2d):
        last_conv_layer = layer

# 마지막 Convolution Layer의 Output(Feature Map) 찾기
last_conv_layer_output = None
# 모델 forward 계산 시 레이어에 해당하는 feature map이 자동으로 저장된다.
def hook_fn(module, input, output):
    global last_conv_layer_output
    last_conv_layer_output = output

hook = last_conv_layer.register_forward_hook(hook_fn)
# ==============================================
```

```python

def imshow(image, title=None):

    image = image.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = std * image + mean

    image = np.clip(image, 0, 1)

    if title is not None:
        plt.title(title)
    
    plt.imshow(image)
    plt.pause(0.001)

# ============이미지 출력하는 과정==================

answers = model(images.cuda())
_, preds = torch.max(answers, 1)

last_conv_layer_output = last_conv_layer_output.detach().cpu().numpy()

# hook을 제거합니다.
hook.remove()

for index, (_pred, _class) in enumerate(zip(preds, classes)):

    # 4개만 출력
    if index > 4:
        break
    
    print(f"예측 클래스: {classes_name[_pred]}\n정답 클래스: {classes_name[_class]}")

    # Feature Map에 따라 크기를 바꿔주어야한다.
    overlay = np.matmul(fc_weight[_pred], last_conv_layer_output[index].reshape(512, 7 * 7)).reshape(7, 7)
    overlay = overlay - np.min(overlay)
    overlay = overlay / np.max(overlay)

    # overlay(np)를 Torch 텐서로 변환
    overlay_tensor = torch.tensor(overlay, dtype=torch.float32)

    c, w, h = images[index].size()
    mask = F.interpolate(overlay_tensor.unsqueeze(0).unsqueeze(0), [h, w], mode='bilinear')
    mask = mask.cpu().detach().squeeze().numpy()

    
    imshow(images[index].cpu())
    plt.imshow(mask, cmap='jet', alpha=0.4)
    plt.show()
# ===============================================
```

### Grad-CAM (Gradient-weighted Class Activation Map)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/cc8bd73e-aa97-422a-8e7c-750fa8e071eb)

CAM은 예측 직전에 GAP을 수행하도록 네트워크의 변경이 필요하다.  <br>
하지만 Grad-CAM은 Gradient Signal을 이용하여 Feature Map을 결합하는 방식을 사용하여 기존의 네트워크의 구조를 그대로 사용할 수 있다. <br>
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/5d80b8cb-4fd4-413f-82d7-7f22c96c866c)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/80462c69-b47b-40d1-99c3-17250e901f61)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/af4fcaa0-223a-41ce-85fa-6d12d02d7614)
![image](https://github.com/hyeon-n-off/hyeon-n-off.github.io/assets/161814308/41bcf6af-f2ff-444b-b7ed-0c25b68fd92b)